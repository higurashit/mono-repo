# architecture of design

- 良いアーキテクチャとは
  - 合目的性
    - 上位目的に沿っているか
  - JIS25001 で定義される品質特性（8 つ）、品質副特性がベース
  - 制約、技術、、、なども鑑みる
  - アーキテクチャによって達成すること
- 良いデザインとは
  - 人間中心デザイン
  - 人間のニーズ、能力、行動を取り上げて、それに合わせてデザインする
  - 開発者体験を高めるデザインを目指す
  - コードを書く時間 << コードを読む時間
    - 安全に、素早くコードを変更できること
    - Ex.コード特定が容易、コード理解が容易、自動テスト
  - 認知負荷を下げる
    - 課題内在性負荷
    - 課題外在性負荷
  - メンタルモデルを作ってあげる
    - ドメインモデル
    - ユビキタス言語
    - 開発者が良いメンタルモデルを構築する
- 良い設計をするために
  - 設計原則
  - 原理は理、原則はルール
  - SOLIF 原則の上位目的は変更に強い設計をするための原則
  - CLEAN（レガシーコードからの脱却）
    - 関心の分離
      - 大きなものをそのまま扱わない
      - 関心事によって分離する
    - 高凝集
      - 分離したそれぞれの凝集度を高くする
      - 余分なものを含まない
    - 疎結合
      - 分割したそれぞれの依存度を下げる
      - 依存する要素数を減らす、呼び出す操作を粗粒度にする
    - 抽象化
      - クライアントにとって本質的で重要なものを抽出
    - 非冗長
      - 冗長性を取り除く
      - 意図が同じ、冗長なコードは共通化する
    - これらの 5 個は互いに良い影響を与え合う
- 設計をどのようにしていくか
  - Level1 アーキテクチャ
    - システムをどのように分割するか
      - サブシステム分割（ドメイン駆動で分割）
        - 事業がドメイン、部門がサブドメイン
        - 音楽配信事業の企画部門
        - イベントストーミングなどの手法でドメイン知識を抽出する
      - サービス分割（デプロイ単位）
        - マイクロサービス vs モジュラーモノリス
        - マイクロサービス化によって得たい能力と、MSA の負を比較する
        - レイヤードアーキテクチャ（業務）、パイプライン（データ中心）
        - クリーンアーキテクチャ、オニオン、ヘキサゴナルはレイヤードの亜種
    - level2 モデル
      - 垂直分割
      - 1 種類のアクターに対して、関連度の高いユースケースをまとめる
      - ポート＆アダプター（ヘキサゴナルアーキテクチャ）
    - level3 コンポーネント
      - コンポーネントの相互作用によってユースケースを実現する
        - 入力ポート、処理フロー、中核ロジック、出力ポート
        - ロバストネス分析（境界オブジェクト、実体オブジェクト、ドメインオブジェクト、の 3 つ）
      - キャストの役割を意識する
    - level4 クラス・関数設計
      - 分割を行いプログラム言語の最小単位に落とす
      - ドメイン観点の分割
        - 値オブジェクト、区分 Enum
      - 技術観点の分割
        - デザインパターン
        - 言語のパラダイムや特性、表現力による
- 設計・実装をどのように進めるべきか
  - 1. ボトムアップ
    - 末端から実装して統合、よくあるパターン
    - 統合のリスクがある（歪な設計、考慮漏れによる手戻り）
  - 2. アウトサイドイン
    - モックを活用し、外側から実装を進める
    - 習得が難しい（実践テスト駆動開発）
  - 3. インクリメンタル
    - おすすめ
    - ユースケースを少しずつ繰り返し統合する
    - ボトムアップをユースケースごとに繰り返していく
      - ハッピーパス → 亜種パス → エラーパス
      - 代表種 ⇨ 派生
    - インターフェースや公開メソッドを定義 → クライアントからの呼び出しを定義 → 実施のコードを定義

# AI が変えた開発のスタイル、そしてアジャイル

- NEC ソリューションイノベータ
- 古い開発と近年の開発モデル
  - アジャイルシフト
  - 短い期間で品質を求められる、AI の登場によりさらに品質を求められる
- CD/UT
  - 自動テスト、自動デプロイ、コンテナ化、マイクロサービス
  - 素早く検証が行える
  - 品質の担保を検証をもって実現、開発者が製品のゴールを語れることが大事
  - UT のテストコードを書くのが大変
    - SOLID の原則の S に忠実であれば、テストコードを書きやすい
    - 綺麗なコード＝テストしやすいコード
  - UT のゴールとは
    - メソッド・関数をテストするだけでない
    - 製品目的を達成できているかが重要
  - リファクタリングする勇気！
- 生成 AI の適用
  - 問題：LLM にテストを生成させてもうまくいかない
    - 結局、関数やメソッドが小さく、インプットとアウトプットが明確な場合はうまくいく
    - 単一責任の原則と、AI の使い方を知ることが重要
  - テストを後から書くと、カバレッジを通すためのテストとなり、うまくいかない
    - ペアプロによる指導、テキストの紹介、AI を使ってみる
  - よりうまく生成 AI を使う
    - テキスト以外のドキュメントに使うには運用コストが高すぎる
    - そのために、全成果物をテキストで出力される
    - それが実践されると、管理先が Git になる！！
    - レビューは issue、プルリクエストに集約される
  - 実際にやったこと
    - 仕様書は MarkDown
    - UML 図、スニペット
- チームビルディング
  - チーム全体でテキストの世界に踏み込むと、アジャイル＋ AI の世界になる
  - ルールを定める
    - 資材管理ルール
    - 製造プロンプトルール
    - レビュープロンプトルール
  - 使ってみる、共有する
    - AI を使うことでアウトプットの品質が変わる（漏れが減る）
    - あたりまえ部分の品質が確保されるため、本質的な観点でレビューができる
    - より高みを目指すプロンプトへ改善していく
- 「便利そうだから使う」からの脱却
  - 採用の目的を明確にする
  - LLM に任せる領域を検討し、使い方をメンバーで考え、ブラッシュアップしながら運用していく
- チームマインド
  - 情けは人の為ならず、はリーダーが成長する要因の 1 つ
  - 自身だけでブラッシュアップして、他の人に共有しない人は伸びていかない
  - 共有の場をどのように持つか
    - 作業を手伝う、見守ったり、ペアワークが効果としては高い
    - 定例会、勉強会などはそれほど効果がない
  - みんなが楽になる
- 生成 AI の課題
  - チームビルディング、コミュニケーションは必要
  - ハルシネーションの看過、プロンプトエンジニアリングが追加で必要なこと

# Gemini in BigQueryu が導く、データ分析の次のステップ：raw データからインサイト獲得までの AI 活用法

- Google Cloud
- Google Cloud で始めるデータエンジニアリング入門
- データ活用の今後
  - データを取り扱う上での課題
    - 専門家依存のデータ分析では時間がかかったり、多角的な分析ができない
    - セルフサービスのデータ分析基盤
  - データメッシュアーキテクチャ
    - データ基盤をドメインごとに作理、遊び放題
    - ガバナンスレイヤ、データプラットフォーム
- データ分析ジャーニーにおける Gemini の活用

  - データの発見・準備
    - 生成 AI によるセマンティックサーチ
    - 自然言語クエリを使用してデータアセットを検索、メタデータおよびユーザタグを検索
  - データの加工・分析
    - データプレパレーション
      - クレンジング
      - Ex. 形式変換、Null 補完、文字列 → 数値変換、大文字小文字変換
      - 都度プレパレーション処理は大変なので定期実行する
    - 生成 AI はメタデータを確認するため、最新化する（人のためにも）
      - description に説明を加える（東京 ↔︎ tokyo）
    - データ分析のコールドスタート問題
      - パッとテーブルを渡されても分析できない
  - データの解釈・評価
    - SQL の内容を解釈して自然言語で返す
  - データの活用・展開
    - ダッシュボードからスライドの自動生成
    - 検索エンジン

# ニンテンドーアカウントへのパスキー導入

- パスキー導入の動機
  - ニンテンドーアカウント：2015 年、164 ヵ国、3.6 億アカウント
  - アカウント分断による体験の分断を避ける
  - ID/PW、メアド認証
    - パスワードの難易度がコントロールできない
    - メールアカウントが侵害されるとアカウントの乗っ取りが起きる、メールもコントロールできない
  - パスキー
    - 端末解除でログイン（指紋認証など）
    - Javascript などで実装可能
    - パスキーの登録
      - 必要な情報をサーバから送信
      - 端末がわでキーペアを生成、秘密鍵をほぞ n
      - 公開鍵の送信、サーバ側で保存
    - パスキーでの認証
      - 必要な情報をサーバから送信
      - 端末側で秘密鍵を使って、アサーションを生成（この際に指紋認証などが必要）
      - アサーションをサーバ側で検証する
    - パスキーのメリット
      - 単一の公開鍵の漏洩だけでは他サービスに影響しない
      - 偽サイトでパスキーを作っても意味がない
      - パスワードのように覚えるものがない
      - 年に 1 回だけ使うサイトも、毎日使う端末と同じ方法で開けられる
- パスキー導入に向けた認証ポリシーの整備
  - 認証ポリシー
    - ユーザ認証を求める場面で、認証手段をどのようにするかのガイドライン
    - 認証手段の 1 つにパスキーを追加した
    - ログイン、重要操作前の再認証、アカウントリカバリ
  - なぜ認証ポリシーが必要か
    - パスキーはパスワードより強力
    - しかし、パスワード認証やメアド認証が残るとサービス全体の認証強度は変わらない
    - サービス全体の認証強度に合わせ、認証ポリシーを定義することが重要
  - ニンテンドーアカウントの性質
    - 守りと使いやすさの両立
    - パスワードよりも高い認証強度かつメールアドレス依存をやめる
  - NIST ALL
    - 認証の 3 要素（知っている、持っている、本人である）
    - ALL1 は単一、ALL2 は複数、ALL3 は複数かつフィッシング体制あり
  - ニンテンドーアカウントの認証ポリシー
    - 認証保証レベルの独自定義（L1: PW のみ, L2: PW+Mail, PW+SMS, PW+OTP, Pass Key のみ）
      - パスキーを求める顧客は、L2 を求める
      - つまり、パスワードのみ、メールのみではログイン／アカウントリカバリができない
    - 認証保証レベルの強化、緩和
      - リスクベース認証としてアタック疑いを検知したら L2 を求める
      - 重要度が高い操作前には L2 を求める（パスワード更新、メアド更新など）
      - 常に L2 を求められると体験が損なわれるため、緩和策を検討
        - パスワード認証（L1）後に、一定時間内に OTP 認証を行うと L2 扱いとなる
    - メリット
      - ルールの見える化により、開発のしやすさやカスタマーサポートの混乱が減った
    - 苦労した点
      - 稼働中のシステムに適用するのは大工事
      - セキュリティの強度と仕様の複雑度のバランス
- パスキー
  - UI ガイドラインに従う
  - パスキーログインができる顧客には ConditionalUI を利用する（入力フォームにフォーカスするとパスキーログインができる）
  - パスキーを使うと Cookie にフラグが登録され、パスキー登録が優先される
  - Nintendo Switch からは QR コード → スマホでパスキー認証が可能
  - Switch と端末が遠くにある場合はリスクが上がるため、数字を入力させるなどの追加インタラクションも追加
  - ブラウザエラーは API 経由でサーバに集計
  - Virtual Authenticators を用意することで E2E テストも可能
  - Hybrid transports でパスキー保持していない端末とパスキーを保持する端末をくっつける？

# 生成 AI - AWS Skill Builder で社内リスキリングを推進！現場エンジニアが語る、新技術普及の勘所

- Works Human Intelligence 　寺尾さん、小島さん
- HR テック、人事課題
- 全社導入
  - 企画、PoC40 名、トライアル 200 名、全社導入 2000 名
- 生成 AI 基盤
  - ナレッジ検索（RAG）
    - 製品サポート、新人・若手の製品理解
  - Slack のスレッド要約機能
  - セキュリティ
    - 情報漏洩対策：Bedrock
    - 利用状況モニタリング：個人レベルのモニタリング
    - 利用ガイドライン
- 生成 AI の普及
  - AI を触って慣れる
    - トップダウン
  - 特定のユースケースで活用
    - ボトムアップ（全社イベントで事例紹介）
  - 非コア業務を AI に委託
    - 業務ステップの分解と部分的な委託（精度の低さをカバーする）
  - コア業務を生成 AI と共創
    - ユーザヒアリングに基づくインタフェースの最適化
  - 利用率が 20%から 40%に増加
- AWS Skill Builder 活用促進
  - AWS Jr.Champion に選出
  - Skill Builder の有償プランを検討する
    - JAM イベント開催
      - メンバーのマンネリ化：同じチームでやる
      - 内容のマンネリ化：イベントに特色をつける、アンケートで題材募集
      - 負け続きのマンネリ化；問題の解説ワークショップを開催

# 組織貢献をするフリーランスエンジニアという生き方

- 竹端さん
- 新しい考え方
- IC(Indivisual Contributer)を求める
- 自由と成長を求めている
- フリーランスである竹端さんの現状
  - 開発
  - アジャイルアクティビティのオーナー
  - イベント出展、技術広報
  - 採用、スカウト、面談
- なぜフリーランスでやる意味があるのか
  - 契約・報酬の考え方がシンプル
    - 有休や福利厚生などの利点も踏まえる必要がない
    - 制度変更に影響されづらい
  - 入るのも辞めるのも手間が少ない
    - 入るまでのリードタイムが短い
    - 提出物が少ない
    - 辞める時も契約が終われば終わり
    - 個人事業主なので社保、国保、iDeCo などで考えることが少ない
  - フリーランス故に自由に動ける
    - 副業ができる
    - 外部発表の許可がいらない
    - 会社の看板を背負わなくて良いし、都合のいい時に会社の名前を使うこともできる
    - 外の知見を企業に還元できる
  - 気を抜いたらすぐ切られる可能性もあるヒリヒリ感
    - 直近の成果や予算などの事情により切られる可能性がある
    - 故に常に精進していくことを考える必要がある
    - 今の場所では難しいと判断したときは他の企業に移りやすい
- 企業側のメリット
  - 企業の枠にとらわれずに外部との交流を持っている
  - 個人事業主として社員とは異なる視点
  - いざとなったら切れる
- フリーランスの給与
  - 社員の 1.5 倍をもらってトントンの世界
  - 収入は増えるが、必要な支出は増える
  - 休めば収入がない、傷病手当もない、年金は国民年金のみということで自分で対策する
  - 貯蓄、民間保険、iDeCo、税理士との契約、、などリスクヘッジにお金がかかる
- この考えに至るまでの経緯
  - 業務内容
    - リードエンジニア、EM
    - 採用、技術広報
    - イベント企画
  - マインドチェンジ
    - テックリード前提だったがチーム立ち上げに関わる
    - 採用、育成、フロー、体制、文化づくり、施策企画、、を実施
    - この時に評価され、自分の特性に気づく
    - 自分が組織に関わって仕切っている方がストレスが低い
    - ただし、フリーランスでは行きたいと思っている

# FPT AI Factory で加速する AI 開発

- FPT AI プラットフォーム
  - AI ファースト戦略、NVIDIA 認定
  - AI 戦略的パートナー
  - パブクラの並びで AI Fctory が存在する
- FPT AI Factory
  - NVIDIA AI Enterprize をベース
  - GPU の専用クラウド、多様で手頃な商品とサービス
  - AI インフラ、スタジオ、推論、エージェント
  - AI インフラ
    - かなり高スペック
  - AI スタジオ
    - プレパレーション、Notebook（RAG 生成も可能）
    - 事前トレーニング、ファインチューニング、モデル Hub（Market Place）
  - AI 推論
    - モデルサービング
      - 完了後に URL が生成され、URL ベースで推論ができる
    - モデルアズアサービス
  - AI エージェント
- Code Vista（Copilot 風）
  - マルチエージェント AI システムによるコーディングの革新
  - BaVista：要件定義を製作
  - CodeVista：コード補助、プラグインとしてインストール
  - TestVista：テスト
  - PmVista：プロジェクトマネジメント

# 学び

- 生成 AI
  - 全ドキュメントのテキスト化
  - 施策実施予定だが、バイナリじゃなくてテキストがいいかも
  - 普及に向けた UI の設定
  - 業務利用基盤として定義、提案時の前提条件に加える
  - 理想と現実的を兼ね備える
  - コード
    - プロンプトエンジニアリングを全てスニペット化して Git 登録
- 格言
  - 日本企業のデータが 1 年に生んだ価値：17 兆円
  - ガイドラインに従う
- データ基盤
  - データ理解
    - 生成 AI でデータをまとめる（≒ 自動データカタログ）
    - これくらい手作りできるでしょ
  - プレパレーション
    - 都度プレパレーションは大変なので定期実行にする
  - 変換クエリ、抽出クエリ
    - コメントを残すルールにする（人も生成 AI も）
  - データ利活用
    - データプラットフォームで守られたデータに対し、自然言語でクエリを吐き出せる
    - メタデータをしっかり記述すれば、いけるはず
    - そのクエリを保存して共有できる、クエリの内容も生成する
    - ダッシュボードも自動生成、ダッシュボードの内容も説明してくれる
- ビジネス
  - 構造化データの分析自動化
    - データを投入する（手動）
    - データカタログ（description）を生成 → 訂正（半自動）
    - プレパレーションルールを生成 → 訂正（半自動）
    - 更新履歴 TBL と stream を生成（自動）
    - DWH テーブル案を生成 → 訂正（半自動）
    - データ利活用ユースケース１（BI）
      - ダッシュボードを設定（手動）
      - DM を自動生成（自動）
      - ダッシュボードを自動生成（自動）
      - レポートを生成（自動）
    - データ利活用ユースケース２（データ提供）
      - データの検索ページを生成（自動）
      - データを検索・DL（手動）
    - データ利活用ユースケース３（データ価値付加）
  - 非構造化データの分析
    - xxx
- モバイル
  - パスキー認証
- AWS Top Engineer 育成
  - Skill Builder の有償プランを検討する
  - ワークショップの開催
