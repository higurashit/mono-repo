# 20240619-20_AWSSummitTokyo2024

## new IDEA

- 講演のヒント
  - 好きなもの、サーバレス、非同期
  - 今日、成功を収めているビジネスはデータビジネス
  - よって、データはビジネス資産であり、代表的な活用は AI（コスト削減、価値創出）、分析（インサイト、アイデアの創出）、BI（意思決定のアジリティ向上）
  - 最初に Purpose があるといい。データ活用のビジョン
    - データ戦略の中にデータガバナンスがあり、データガバナンスの中にデータ品質がある？
    - データ戦略、データガバナンスはデータ活用とビジネスメリットまで含めた考え、攻めの IT。ただしコストをかけたくない
    - CDO のほぼ半数 (46%) が、生成 AI の実施における最大の課題の 1 つがデータ品質
    - 利用できる状態にする、見つけられるようにする、安全に保つ
    - 利用できる状態にするには、データ品質が重要（データガバナンスのメモを参照）
  - データは AI/BI における戦略的資産。資産価値を減らさないことが重要
    - Good AI needs good data.Good data needs good AI.
    - AI の民主化
    - AI は泥臭い部分こそ使えるもの
  - MDM は守りの IT 投資の肥大化を防ぐ
  - データがキモなので、自社以外のデータを使うことも重要、ハブ
  - データがキモなので、自社のデータを使わせることも重要、仮名匿名
    - 生成 AI の入力で使う
  - アナリティクス、データベース、データレイク、データガバナンス、ML
    - 私の得意分野である AWS に加え、NTTD グループの知見やノウハウを組み込んで高速かつ高価値なサービスとして提供
  - 格言を使う
    - 普遍的な価値である、俊敏性、拡張性、柔軟性を謳う
    - クラウド、パッケージの利用
  - imforce Datalabtics データハブ（誤解がないように運び屋の名前）
- ビジネスモデル
  - 人依存からの脱却
    - 基盤導入サービス：1000 万＋カスタマイズ、フルスクラッチ
    - JMDM プラグイン：カタログ化
    - データハブ：1000 万＋カスタマイズ、顧客専用のクラウド環境を用意して繋げる
    - 最初にプレスリリースを書くことで、顧客に必要のないものは作らない
  - MDM
    - 分析クエリをテキストから生成：MDM 拡張、Querybook という OSS を組み込む
    - データ抽出の要件を伝えるコスト、作るコスト、繰り返しコスト
    - Amazon Q Generative SQL in Amazon Redshift クエリエディター
  - Zero-ETL
  - 生成 AI
    - 入力と出力
    - 入力/出力をカスタマイズするのが生成 AI アプリ
    - 入力
      - 基本的にテキストなので、RAG へのインプットにもなり得る（会話履歴）
      - 状況的文脈（アプリデータ、ログデータ、
      - 意味的文脈（マニュアルなどの PDF、HTML、Email など）
    - 出力
      - テキストの場合は、RAG へのインプット

## 学んだこと

- 生成 AI と開発
  - Amazon Q Developer
  - IDE で Amazon Q Developer を利用すると、「要約する Lambda を作って」で作ってもらえる
  - IDE で Java、Python 両方作成できる
  - Lambda 実行時にエラーとなったら、Amazon Q に聞くボタンでトラブルシューティングできる
  - Bedrock ナレッジベースと Opensearch を組み合わせて、RAG 化ができる
- 生成 AI とアナリティクス
  - AWS のラインナップ
    - 下段は基盤
    - 中段がモデル：Bedrock
    - 上段が生成 AI を搭載したアシスタント：Amazon Q（業務向けの Business と 開発向けの Developer がある）
  - 全体像
    - Amazon Q data integration Glue（自動 ETL スクリプト生成）
    - Amazon Datazone
      - メタデータの中で最も重要なのはビジネスメタデータ
    - Redshift クエリエディター v2 / Amazon Q Generative SQL in Amazon Redshift クエリエディター
      - テーブルのロード
      - 日本語で SQL を依頼（コホート分析などのワードを使っても OK）
      - Notebook に反映して実行
      - 結果の可視化が可能
    - 可視化（Quicksight）
      - BI の課題
        - BI ツールの独自仕様を理解する必要がある（学習コスト）
        - BI ツールが高機能になるほど、クリック、ドラッグ＆ドロップの増加、メニューの増加
        - データから得られたもののみが分析対象
        - ビジネスレポート作成に時間がかかる
      - QuickSight の Gnerative BI
        - 自然言語によるダッシュボードドラフトの作成、計算フィールドの作成、見た目の微調整
        - 自然言語によるデータとの対話、エグゼクティブサマリの表示、ダッシュボードに対する質問、グラフで回答
        - 自然言語によるデータストーリーテリングの生成
          - 「xxx が急増しているため、解決プランを提示してください」みたいな指示
          - プレゼンテーションが自動生成される
    - データアナリティクスにおける認定的飛躍の加速
      - 仮説、分析、解釈、アイデア出しを、人と生成 AI が相互に作り出し、認知が飛躍する
    - ビジネスユーザとデータアナリストの関係の変化
      - 重なりが増える（ビジネスサイドでアナリストできる、データアナリストが意思決定できる）
      - データアナリストは生成 AI へのインプット力、共存姿勢、基盤構築力が必要
- データガバナンス
  - Fortune1000 の 94 企業のうち、54%がデータ戦略を持っている
  - Gartner レポートではデジタルビジネスを行う企業の 80%がデータガバナンスを失敗する
  - データ戦略の最優先事項はデータガバナンス
  - データガバナンスはイノベーションを加速するためのガードレール
  - 昨今はデータサイズと種類の増加、データ元が分散している、ビジネスユニットが増えている
  - AWS フレームワーク、Curate ,Understand, Protect、ビジネス要求を満たすものから手をつける
  - Curate
    - 機密情報（個人情報、機密事項）の特定と対処、データ品質管理（一貫性、精度、完全性、整合性）
    - 目的は利用者が自信を持ってデータをビジネスに活用することができる
    - データ品質は 0.5%で誤ったとしても、意思決定は 30%間違える
    - ETL パイプラインの中で機密情報への対処と品質管理を行う
      - 機密情報は AWS Glue のビルトイン Detect Sensitive Data で PII（個人識別情報）を自動識別
      - データ品質は Glue Data Quality により、データスキャン、統計、データ品質ルールなどを ML で自動設定
    - 生 S3 → ETL パイプライン → Curate S3 ← 品質監視 という考え
  - Understand
    - Amazon DataZone を利用する
    - データプロデューサーとデータコンシューマがいて、マーケットプレイスのようにデータ共有できる
    - Redshift、S3、Snowflake、Glue DataCatalog などをメタデータを DataZone に入れる（リンク）
    - メタデータがあることで、どこにあるのかを検索できる、活用できるのかが分かる、信頼できるのかが分かる
      - データポータルによりどこにあるのかを検索、アクセス申請、分析
      - ビジネスメタデータ機能により、活用の仕方（Readme）やタグなどを設定できる
      - データ資産のサマリーの自動生成、活用事例の自動生成がされる
      - データ品質メトリクスを表示することができる
  - Protect
    - データセキュリティ管理は組織を越えると途端に難しくなる（ポリシー、信頼性、手順）
    - DataZone により、データ検索、アクセス申請、接続・分析・活用、ポリシー担保が実現できる
  - データ利用のフロー
    - プロデューサープロジェクトを作成し、ユーザー・ツール・データを入れる
    - コンシューマープロジェクトを作成し、ユーザー・ツール・データを入れる
    - データポータルからアクセス申請を行う
    - プロデューサーがアクセス権を与える（Redshift, LakeFormation GlueTable は自動付与できる）
    - データに接続し、分析・活用
  - データガバナンス推進
    - ビジネスとデータの両方が分かるデータスチュワードを企業内から専任で選出する
    - データポリシーを管理するデータオーナー
    - データ変換、活用をサポートするデータエンジニア
    - ポイントは「特定のビジネスイニシアチブをサポートする形」から始める
    - ただし、データガバナンスの全体像、未来を踏まえて進める
    - データガバナンスの実行の責任主体がコントロールする
    - 誰もがコンシューマになりたがるが、プロデューサーにはなりたがらない
  - 参考
    - AWSData governancemaster class / youtube もあるよ
- 生成 AI のメリットと事例
  - 自動設計、価格最適化、説明など。生産性向上・コスト削減・付加価値創造
  - 分析クエリをテキストから生成：MDM 拡張、Querybook という OSS を組み込む
  - AWS サービス
    - Amazon Q は生成 AI の元データとして、43 のコネクタを利用して企業データに接続する
    - Amazon Q developer で推論結果の透明性を担保する
    - knowledge bases for Amazon Bedrock で非構造データを自然言語処理＋ RAG
  - 生成 AI は、顧客起点文化・小規模チーム・頻繁な実験がビジネスインパクト創出の方程式
    - 我々が EBC になる、AWSExecutive Insights
    - ML Enablement Workshop
    - 頻繁な実験は MLOps
  - レビューのサマリなど、何かをサマって人間が書く前のテンプレートにする
  - 分類や数値以外の出力を人間が実施している箇所
  - ファインチューニングは基盤モデルのチューニング
  - RAG を利用する。全てのデータを入力値にする
  - プロンプトエンジニアリングの自動化、RAG でプロンプトエンジニアリングを自動生成
  - AWS で RAG を実装する場合、入力 → Bedrock → S3 → Bedrock → 出力ができる
  - データの質が高いこと、組織全体でデータを共有すること、意思決定に使うことが前提
  - 生成 AI アプリの事例
    - 船、ホテル、旅客機などを持っている企業
      - ビッグデータ活用、アジリティ、セキュリティの向上によりクラウド移行
      - 休暇と予約、目的地、、などに
      - M＆A を繰り返して,大きくなってきたことによる、老朽化、断片化、サイロ化
      - リアルタイムパーソナライゼーション
        - データソース、データパイプライン、特徴量エンジニアリング、モデル開発、モデルデプロイ、提供、活用の流れ
        - データサインティストのリソースを集中
        - 大規模かつ高速なデプロイが可能
        - 120 日 →40 日、3→15 モデルデプロイ、6→3 チーム
    - 大手銀行
      - コンテンツ制作が得意領域ではないため、ボトルネック
      - SM を利用して半年〜1 年かかっていたことで AI モデルを 5 倍利用できるように
      - コンテンツのパーソナライゼーション、コンプライアンスチェック、自動フィードバック
      - クリック率 4 倍、口座開設 9 倍
    - Chocozap
      - マニュアルチャットボット
      - 利用率、改善効果により KPI 影響を図る
    - カラクリ株式会社
      - カスタマーサポートの自動返答
      - ファインチューニング
    - エフピコ
      - 営業日報作成・分析体験の向上
      - 700 時間/月
    - 第一興商
      - 会話記録
    - サイバーエージェント
      - セキュリティの質問の半数近くを生成 AI で作成い
  - GenU を参考にする
  - MLOPs
    - クラウドベースでスケーラブル、DevOps、セキュリティ
    - 並行で繰り返す AI 開発
    - Amazon M5（生成 AI）
    - ML Enablement Workshop
  - クラウドネイティブが進むと機械学習の活用が進み、生成 AI の活用が進む
  - Adobe Firefly
    - 生成 AI による塗りつぶし、テキストへのスタイル適用
    - 独自で保有している画像を利用することで、著作権に対応
    - フローに組み込むことができる
    - 歴史
      - 2016 年に顧客体験改善に取り組む
      - 2023 年に数十人の研究開発チームで独自基盤モデルの開発
      - リリース済み数個、裏では数十個の開発、1 年に 300 デプロイ
  - Pinterest
    - １秒間に数億回の推論
    - １秒間に 8000 万のイベント
    - 毎日モデルのデプロイ
- データ基盤コスト
  - データ活用におけるコストの関心が高まっている
  - シンプルなデータレイク
    - 生データバケット、加工済みバケット、データマートバケット
    - 加工には EMR や Glue を使う
    - データマートは Athena によりアドホックや可視化を行う
  - データ基盤のコスト課題
    - サービス横断でコストが発生
    - データ量と処理に強く依存する
    - コストの予測が難しい
  - well-archtected の CFM フレームワーク
    - これをデータ基盤に適用、特に可視化と最適化
  - コストの内訳
    - ストレージ（サイズ）
    - データ転送（サイズ） ※ 特にインターネット、リージョン、AZ をまたぐ場合
    - データパイプライン（コンピュート）
    - クエリ（コンピュート、スキャンサイズ）
  - コスト可視化
    - 全体は CostExplorer
      - 無料、14 ヶ月遡る
      - コストの詳細が確認できる
    - ストレージ
      - S3 Storage Lens
      - 平均オブジェクトサイズが小さい場合の改善ができる
      - アクセス頻度の低いデータの特定
  - コスト最適化
    - ストレージ
      - ストレージクラスの最適化
        - アクセス頻度がわかる場合はストレージクラスを選択する
        - Amazon Athena はどのストレージクラスでもアクセス可能
        - アクセス頻度がわからない場合は S3 intelligent-Tiering で自動最適化
      - S3 ライフサイクルの活用
        - 1 年後に Glacier Instang Retrieval、2 年後に Deep Archive など
        - 5 年後に削除など
      - データの圧縮
      - 不要なデータ、一時的なデータの削除
    - データ転送
      - データ転送経路の最適化
        - ❌：NAT GW, IGW を利用して S3 接続
        - 🙆：GW エンドポイントを利用して S3 接続
      - データのローカリティを考慮した設計
        - リージョンをまたがないように設計する（リージョンごとに EAI を構築するとか）
      - 圧縮による転送効率の向上
        - 大容量は圧縮してから転送する
      - 必要最小限のレプリケーション
    - データパイプライン
      - 料金プランをデフォルトのままにしない
        - Glue Flex Jobs を利用すると 34%削減できる
      - オートスケーリング、サーバレス
        - EMR Managed Scaling
        - Glue Auto Scaling
      - ジョブのチューニング
        - 典型的なパフォーマンスボトルネックに対する見解はドキュメント化されている
      - 処理対象の削減
        - 2 桁%の削減実績あり
      - 差分データ反映の最適化
        - Upsert はコンピュートが多いので、最適化していく
        - オープンテーブルサポートにより Merge into クエリを使うことで
        - データレイクは Iceberg ,Hudi,DletaLake、DWH は Redshift が対応している
        - 2 桁%の削減実績あり
      - データクオリティ管理の導入
        - 誤ったデータ、欠損データなどが混入することで無駄なコンピュートが発生
        - Glue Data Quality によるデータクオリティチェック
    - クエリ
      - データレイアウトの最適化
        - Athena は Pay per query（サイズ）と Pay per compute（キャパシティ確保）がある
        - Pay per compute の場合、サイズによらないというのが特徴
      - データ形式や圧縮形式の最適化
      - クエリのチューニング
        - Athena コストベースオプティマイザ
        - Top 10 Performance Tuning Tips for Amazon Athena（参考ドキュメント）
      - クエリ結果の再利用
        - Athena の機能でキャッシングがある
        - 無料で使える
      - フェデレーテッドクエリの活用
  - コスト可視化、最適化、実践、予測のサイクルを繰り返し実施することが重要
- AI ✖️ マーケティング
  - AI により訴求軸を発見、コンテンツの自動生成支援、効果予測、届ける部分？
  - AI ペルソナ 100 人で新しい提案をもらう
  - ユーザの入力を AI ペルソナに入れる
  - 最終的にトークスクリプトを生成する
- サーバレス
  - サービスフルなサーバレス
    - Lambda は Transport ではなく Transform に活用する、ロジックが含まれていること
    - migration する場合は、Lambda に全ロジックを入れるのではなく、API GW や S3 への役割移管、責務による分割を考える
    - 1 API 1 Lambda でなく、get 群、update/create 群、delete 群などに分けるのもあり
  - オーケストレーション（StepFunction）とコレオグラフィ（EventBridge）の使い分け
    - デモアプリ（ServerlessVideo）
    - 選択的なサーバレスコンピュートができる
    - EventBridge bus により StepFunctions を完了させる（＝ JP1 の代わり？）
  - コード削減のアイデア
    - StepFunctions から DynamoDB を直接呼ぶ
    - API GW の Lambda プロキシでなく、VTL 経由で直接 DB に登録する
    - DynamoDB から EventBridge pipes を経由して EventBridge event bus にデータを送る
    - Bedrock の呼び出しも直接
    - Public API の呼び出しを直接行うことでエラーハンドリングが容易になり、テストステートも可能
  - 作成したものを人間にフィードバックを依頼し、選択させる
    - StepFunctions の呼び出しパターン
      - リクエストーレスポンス
      - ジョブ実行（.sync）
      - コールバック（.waitForTaskToken）
    - コールバックパターンを使うことで、人間の承認が行える
    - 結果をブラウザに表示 → ユーザは結果を選択する（.waitForTaskToken）というフロー
    - StepFunctions は Prompt Chain モデルとの相性が良い
  - サーバレス ≠ Lambda でなく、StepFunctions や他のサービスに寄せる。EventBridge event bus で相互連携
- 生成 AI とサーバレス
  - デモアプリ（ServerlessVideo）
    - 動画から複数のタイトル、説明を作成する
    - Amazon Bedrock を利用してタイトルと説明文を生成する
      - StepFunctions と Amazon Bedrock の統合
      - StepFunctions と Transcript は直接繋げる
      - 呼び出しパターンの Invoke Model は直接 or S3 のプロンプト
      - 呼び出しパターンの Create Model Custmoization はファインチューニング後に実行できる
    - Bedrock と Public API による複数タイトルの生成を行う
      - StepFunctions の Redrive 機能により、失敗したステートから再開できる
- 生成 AI 用の基盤アーキテクチャ
  - 生成 AI では CX 向上、生産性向上、コンテンツ作成、ビジネスオペレーションの改善が狙える
  - LLM は大規模モデル（Foundation Model：FD）の 1 つのサブセット
  - LLM の課題
    - ハルシネーション（誤答）、曖昧な応答（知らない）、ナレッジカットオフ（古い）
  - モデルのカスタマイズ
    - 独自モデル構築 / ファインチューニング / 文脈内学習（In-Context Learning）
    - 文脈内学習はモデルの再学習が不要
  - モデルに存在しない知識にどう応答するか
    - RAG 検索拡張性性を利用する
      - Retrieval / Augmentation / Genaration の順序を表す
      - コンテンツ品質、文脈理解、リアルタイムデータ要約
    - 文脈情報を RAG により LLM へのプロンプトに含める
      - 状況的文脈：会話履歴、名前、履歴、住所など
      - 意味的文脈：セマンティックコンテキスト、意味的に関連したデータ
  - 文脈情報をプロンプトに追加する例（自動車保険）
    - 会話履歴を蓄積し、前後の情報を渡す
    - 状況的文脈を取り出す（A さんの住所はこれで、いくらの自動車を買っている）
    - 意味的文脈を取り出す（最新の自動車保険プラン）
  - このような文脈情報を適切に管理・運用するためのデータ分析基盤が必要
  - 文脈情報管理基盤のベストプラクティス
    - 非構造化データを取り扱えること
      - 状況的文脈は RDB／NoSQL などに格納される（アプリデータ、ログなど）
      - 意味的文脈はベクトルデータベースに格納されることが多い（PDF/社内文書/画像/HTML/Email）
      - 状況的文脈は構造化（半構造化）データであることが多い
      - 意味的文脈は非構造化データであることが多い
      - 非構造化データからテキスト情報を取り出し、数値化（ベクトル埋め込み）することで、単語間の意味と関係を表現する
    - リアルタイムにデータを扱えるデータパイプライン
      - 会話履歴、ユーザ登録情報、提供サービス名などを
    - ユーザに価値のあるデータを作り出せる
      - 関連性の高いデータが含まれ、不必要んデータが含まれていない
      - データ品質が高い
      - 回答してはいけない個人情報などが含まれていない
  - 全体像
    - データソースは状況的文脈（Log/APPData/UserProfile）、意味的文脈（PDF/HTML/Email/Image）
    - データ収集
      - Glue、Kinesis、MSK（Kafka）
      - 柔軟に非構造化データ含め取り扱える
    - （必要に応じて）データ処理
      - Glue, EMR, Apache Flink
      - Snowflake でもいいんじゃない？
      - Glue Quality でもいいんじゃない？
    - データレイク
      - S3（生データ、抽出データ）
    - データストア
      - 状況的文脈
        - Redshift
        - Aurora
        - （会話履歴のようにリアルタイム性を求められる場合）DynamoDB
      - 意味的文脈（ベクトル埋め込み）
        - Aurora（pgvector）
        - OpenSearch
    - データパイプラインとすることが大事
- 非同期（サーバレス）
  - マイクロサービス化を API によって実現する場合、結合度が高くなる
  - サービスが増え、複雑化するほど、依存関係が強くなり結合度が高くなる
  - 同期的な API の課題
    - 障害影響
    - クライアントへの統一した体験
      - ノイジーネイバー対策、高スループット対策、
    - HTTP リソースやメソッドごとに要件が複雑化
  - 非同期アーキテクチャパターン
    - 非同期レスポンスパターン
      - サービス呼び出しイベント発行後、終了する
      - 処理結果は WebSocket で受け取る
      - モバイル決済（AU pay）は SQS イベントで実装する
      - 結果を受け取りたい POS/アプリは、処理結果取得用の WebSocket 通信を API GW を用いて行う
      - 結果を受け取りたい POS/アプリは、登録 API 発行を行う
      - コネクションは DynamoDB に持つ
      - 処理環境後に WebSocket のコネクション情報を利用して通知を返却する
    - トラフィック急増の課題
      - リソースのプロビジョニングだと余剰リソースが発生するが、オートスケールでは間に合わない可能性がある
      - プレイリスト配信サービス（USEN）
      - 店の雰囲気、時間帯、天候に合わせて最適な BGM を提供
      - リクエストトラフィックは North-South トラフィック、マイクロサービスを East-West トラフィックと呼ぶ
      - トラフィックの終端を North に寄せる（要は SQS で終わらせる、CloudFront で終わらせる）
    - キャッシュ有効期限を超えた場合のレスポンス低下
      - Sansan のリアルタイムレコメンデーション
      - レコメンドのキャッシュ化を行なっている
      - キャッシュが古い場合、古い結果を返した後にレコメンド再作成、キャッシュ更新を行う（Next の ISR の考え）
    - 非同期による分割統治
      - コンポーネント分割、個別に管理する
      - POS データ処理（ダイソー）
      - S3 → SNS → SQS → Lambda → S3 を 1 セットとしてそれを繋ぐ
      - StepFunctions によるワークフロー化（アダストリア同様）
      - StepFunctions の Map state 機能を用いると、元の csv ファイルに 100 行あれば 100 並列で実行できる
        - 10%, 20 件失敗だったら全体を失敗にすることもできる
    - セキュアなアップローダ
      - API Gateway は 10MB 制限がある
      - コーセーのリモートカウンセリングアプリ
      - ユーザ登録などは同期的処理
      - 画像アップロードは S3 に直接アップロードする
      - API GW 経由で署名付き URL を発行することで S3 に対するアップロード権限を生成し、クライアントに返す
      - クライアントは署名付き URL でアップロードすることができる
- Glue を用いた ETL
  - モダンなデータ分析基盤のアーキテクチャ
    - データソース（DB/ストリーミング/ファイル）
    - データレイク
    - データウェアハウス（SQL エンジン）
    - 活用（BI/分析/AI）
  - Glue とは
    - データ統合サービス
      - データレイク、データメッシュの実現（？？）
      - ETL として柔軟性の最適化
      - カタログ化
      - ペタバイト単位の処理
      - 機械学習データの準備
  - Glue ジョブの開発
    - 計画/設計/実装/テスト/デプロイ/メンテナンス
    - 開発（実装/テスト/デプロイ）
      - ビジュアル形式によるノーコード/ローコード実装
        - Glue Studio による実装
          - 読み込み/書き込みは 100 以上（Snow ,BigQuery,Salesforce もあり）
          - 変換は 40 以上（Spark SQL、カスタム変換もあり）
        - Glue Studio によるテスト
          - Glue Studio Interactive Data Preview
          - 視覚的に各ノードでどうなっているかを確認できる
        - Glue Studio によるデプロイ
          - Sava ボタンでデプロイされる
          - Worker やノード数も設定可能
          - Git 連携も OK（CodeCommit, GitHub, GitLab, Bit bucket）
          - デプロイの実装例
            - Glue Studio → Git → 設定変更 → Glue Studio（本番）
            - Git → Glue Studio（開発） → (sync) → Glue Studio（本番）
      - コーディング実装（Jupyter Notebook の利用、統合開発環境（IDE）の利用）
        - Glue Studio でプレ実装
        - Amazon Q data integration in AWS Glue でプレ実装
        - コーディング開発の実装
          - Docker 環境あり
          - Jupyter Notebook での実装も可能
        - コーディング開発のテスト
          - pytest によるテストが可能
        - コーディング開発のデプロイ
          - API 系（CLI）、IaC 系（Cfn, CDK）どちらでも OK
      - 実行管理
        - Glue workflows
          - シンプル
          - 移行データ作成はこっちかな
        - StepFunctions
          - AWS サービスとの連携
        - MWAA（Amazon Managed Workflows for Airflow）
          - Airflow を利用する際に採用
    - 運用（メンテナンス）
      - Well-Architected フレームワーク
      - ワークロードの健全性
        - Stepfunctions を使い、エラー検知、通知まで仕込む
        - EventBridge を使い、Lambda 経由で通知する
        - Glue Studio 上で調査する機能がある（CloudWatch ログへのリンクもある）
        - ログについて
          - Glue のエラーカテゴリが設定されている
          - Continuous Logging の設定を ON にして Logger を GlueContext から取得して実行することで、リアルタイムログの確認が可能
        - メトリクスからメモリ/CPU の使用率を確認する
        - Serverless Spark UI タブから実行状態やパフォーマンスボトルネックの確認が可能性
        - （参考）猫でもわかる ETL パフォーマンス・チューニング
      - アクセスコントロール
        - ジョブを作成/実行する権限
        - データソースにアクセスする権限
          - Glue Connection を利用して接続のための情報を全て格納する
          - Glue Connection から認証情報を格納した secrets manager を利用することが可能
          - AWS LakeFormation を利用して S3 へのアクセス制御を一元的に行える
        - 開発者ごとにロールを分けることで、本番環境への誤操作を防止する
- アーキテクチャ道場
  - マルチリージョン、マルチ AZ のクレジットカード会社
    - グレー障害、ブラウンアウトの状態があることを知っている、検知・対応したい
    - Route53,ALB,EKS（多段）、Aurora（マルチリージョンクラスタ、リージョンレプリケート）
    - AZ 障害はブラウンアウト
      - 回答 1
        - 前提として、切り離せるように AZ を跨ぐ通信、処理を極力排除する
          - ALB のクロスゾーン負荷分散をオフにする
          - AZ ごとに Fargate Profile と Deployment を作成し、フロント・バックが全 AZ に存在するようにする
          - フロントからバックへの向き先は自分の AZ とする
          - Aurora のリーダーエンドポイントは AZ を意識しないため、各 AZ のカスタムエンドポイントを作成して向き先をカスタムエンドポイントにする
          - 書き込みエンドポイントは AZ を跨がせる
          - AZ ごとにクラスタを構築すると一貫性が失われる
          - シャード分割では冗長性が失われる
        - 障害を検知する
          - 2 つのケースを想定（AZ 内部の障害、AZ 境界の障害）
          - 内部障害は AZ へのリクエストでエラー率、レイテンシが増加
            - ALB の CloudWatch アラームで、AZ 単位のエラー率、レイテンシ
              - エラー率を 3%と設定し、5 分中 3 分超えていたらアラート
              - レイテンシを 100ms と設定し、5 分中 3 分超えていたらアラート
              - 上記を or でくくったアラームを作る
          - 境界障害は DB へのエラー率、レイテンシが増加
            - 各 AZ に NGW?NLB?を用意し、DB
          - ただし、リージョン障害、プライマリインスタンスの単体障害でも上記状態となるため、除外条件に入れる
            - 他 AZ が同状態になっていないことを条件に入れる
            - 他 AZ が境界障害になっていないことを条件に入れる
            - 上記を設定した複合アラートを設ける
              - AZ1 の内部障害 or AZ1 の境界障害
              - AND（AZ2,3 で内部障害起きていない
              - AND（AZ2,3 で境界障害起きていない）
        - 隔離する
          - アラームから SNS→Lambda 経由で Route 53 ARC による隔離
        - QA
          - プライマリ DB が落ちてたら？
            - フェイルオーバーする。境界障害が AZ1,2,3 で起きていることで発火
  - 依存性障害への対応
    - CloudFront、S3、ALB、ECS、DDB（各 AZ の DAX 経由）
    - ECS では 3rd Party サービスが動いている
    - アプリケーションの品質が 3rd Party に依存する
    - プロキシサービスにより 3rd Party へのリクエストを制御する
    - 負荷の緩和
      - バックオフ、サーキットブレーカー、レートリミット
    - 障害影響
      - サーキットブレーカー、非有同期通信
    - 同期書き込み、非同期書き込み、同期読み込み、キャッシュ読み込みの４パターンを受け付けるプロキシサービス
    - プロキシサービス（左から）
      - アプリケーション
      - プロキシサービス
        - リクエストハンドラー（API GW ＋ Lambda）API GW はプロキシへのレートリミットを入れる
          - 非同期の場合は SQS、処理状態は DDB に入れる
        - キャッシュストア
          - DDB で実装
        - サーキットブレーカー（StepFunctions の Express Workflow ＋ Lambda ＋ DDB）
          - サーキット状態取得 Lambda、サーキット状態更新、エグゼキューター（3rd Party を実行）
        - バックオフリトライ（〃）
        - レートリミット（エグゼキューターで実現、トークンは DDB に保存）
      - 3rd Party サービス
    - プロキシサービスをコンテナ化して Side Car 化しても OK

## 心に残す

- 食品の素材（種）は未処理であるほど消費期限が早いため画像処理 AI で対応
- 格言
  - 干し草の中から針を見つける
  - Good AI needs good data.Good data needs good AI.
  - 10 年後に残る普遍的なものにこだわる
    - 早い、安い、うまい：たこ焼き屋で考える
    - 俊敏性、拡張性、柔軟性
    - パーソナライゼーション
  - 世の中に追従するには、繰り返しデプロイして FB を受けること
  - CDO のほぼ半数 (46%) が、生成 AI の実施における最大の課題の 1 つがデータ品質
    - https://aws.amazon.com/jp/blogs/news/aws-pi-day-2024-use-your-data-to-power-generative-ai/
  - Everything fails, all the time
  - if you cant see, you cant change
  - 差別化に繋がらない重労働
  - Zero-ETL
  - 同期的なシステムは、サービス品質の最も低いものがシステムの品質となる
  - Shift-North の考え方（CloudFront、SQS）
- AI changemaker という組織がある
- Claude 3 Opus は世界一、Amazon Bedrock で 7 月より利用可能
- ユースケースごとの期間、コストを見積もる
- 生成 AI は出力が大きく変わった＝そこに価値がある
- クラウド導入フレームワーク（CAF）でクラウドのメリットを語れるようにする
- マイクロサービスの考慮点（トレードオフ）
  - グレイスフルでグラデーション（優美な劣化）
    - 一部のコンポーネントが停止しても、システム全体は停止せずにサービスを提供し続ける
  - リトライとエクスポネンシャルバックオフ
    - 繰り返し発生するボーアバグと、特定状況下で発生する一時的なハイゼンバグがある
    - ボーアバグは通常本番では起きない、ハイゼンバグへの耐性が求められる
    - 自動リトライかつ待機時間を延ばすことで過負荷の抑制
  - サーキットブレイカー
    - サーキットブレイカーはサービス間に配置する
    - エラーが続くとサーキットブレイカーはそのサービスにリウエストを投げない
    - 繰り返しのリトライで長時間の待機を防いだり、下流サービスのさらなる悪化を防ぐ
  - データ整合性の担保
    - 強い整合性、結果生合成（Saga パターン）の見極め
    - Saga パターンは、StepFunctions フローの中で、エラー時の補償トランザクションも実装する
  - 可観測性
    - UX の観測性
  - 定期的なテスト
    - カオスエンジニアリング、ゲームデイ
  - サービス中断時の影響が大きいほど、複雑さのトレードオフを考慮してマイクロサービスアーキを活用する
  - well architect も見る
  - イベントソーシング＋ CQRS も行う
- ストレージはライフサイクルもセットで考える
- AD 環境のロール制御をもうちょっとしっかりした方が良いかも
  - Assume Role で本番手作業、など

## 聞いたセッション

- 6/19 基調講演
  - 1150C ビジネス価値を最大化！クラウドマイグレーション x 生成 AI
  - 1250C AWS でレジリエントな分散システムを構築するためのデザインパターン
  - 1350C データ × 生成 AI - 事例から学ぶビジネスインパクト創出の方程式
  - 1450B AWS で実現するデータガバナンス
  - 1550B 生成 AI が変える、データアナリティクス
  - 1650B データ基盤のコストを最適化するベストプラクティス
- 6/20 基調講演
  - 1150A サーバーレス開発のベストプラクティス～より効果的に、より賢く使いこなすために～
  - 1250A AWS で実現する生成 AI データ分析基盤構築のベストプラクティス
  - 1350K 同期という思い込み世界は非同期で構成されている
  - 1450C 実践! AWS Glue の ETL 開発運用ベストプラクティス
  - 1550AB アーキテクチャ道場 2024！
